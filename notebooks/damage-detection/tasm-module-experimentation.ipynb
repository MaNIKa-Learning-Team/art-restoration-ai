{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef8d9538-222b-4739-b9f3-84fa36abefa1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T00:10:15.637647Z",
     "iopub.status.busy": "2025-05-29T00:10:15.636065Z",
     "iopub.status.idle": "2025-05-29T00:10:15.646303Z",
     "shell.execute_reply": "2025-05-29T00:10:15.643895Z",
     "shell.execute_reply.started": "2025-05-29T00:10:15.637560Z"
    }
   },
   "source": [
    "# tensorflow_advanced_segmentation_models Experimentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1907d46b-887f-4ef5-bd77-b2d2baf1c108",
   "metadata": {},
   "source": [
    "**NOPE, this doesn't seem to work.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b892188-6fc2-4875-aae2-403924170b22",
   "metadata": {},
   "source": [
    "This notebook's code was based on https://github.com/JanMarcelKezmann/TensorFlow-Advanced-Segmentation-Models/blob/master/examples/TASM_Example_1.ipynb and ChatGPT explanations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876d1c08-4111-4cf9-8221-6be9e808f903",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45c2bde9-bd35-43c2-bf72-c2ab595f97f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T10:45:28.033270Z",
     "iopub.status.busy": "2025-05-29T10:45:28.033000Z",
     "iopub.status.idle": "2025-05-29T10:45:40.158544Z",
     "shell.execute_reply": "2025-05-29T10:45:40.156465Z",
     "shell.execute_reply.started": "2025-05-29T10:45:28.033234Z"
    }
   },
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import shutil\n",
    "from time import time\n",
    "\n",
    "# Third-party libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Deep learning and augmentation libraries\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import albumentations as A\n",
    "import tensorflow_advanced_segmentation_models as tasm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ed4a32-4acf-4a3b-a57a-ca5a5a9bf11c",
   "metadata": {},
   "source": [
    "## Split dataset to train-val-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0b3983d-65e0-4c68-875c-0ffdea374557",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T10:45:40.160846Z",
     "iopub.status.busy": "2025-05-29T10:45:40.160208Z",
     "iopub.status.idle": "2025-05-29T10:45:40.169196Z",
     "shell.execute_reply": "2025-05-29T10:45:40.167770Z",
     "shell.execute_reply.started": "2025-05-29T10:45:40.160804Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Input directories\n",
    "# damaged_img_dir = '../../data/damaged-and-mask-dataset/generated-damaged-images'\n",
    "# damage_mask_dir = '../../data/damaged-and-mask-dataset/generated-damage-masks'\n",
    "\n",
    "# # Output directories\n",
    "# train_img_dir = '../../data/damaged-and-mask-dataset/img-with-val/train'\n",
    "# val_img_dir   = '../../data/damaged-and-mask-dataset/img-with-val/val'\n",
    "# test_img_dir  = '../../data/damaged-and-mask-dataset/img-with-val/test'\n",
    "\n",
    "# train_mask_dir = '../../data/damaged-and-mask-dataset/mask-with-val/train'\n",
    "# val_mask_dir   = '../../data/damaged-and-mask-dataset/mask-with-val/val'\n",
    "# test_mask_dir  = '../../data/damaged-and-mask-dataset/mask-with-val/test'\n",
    "\n",
    "# # Create directories if they don't exist\n",
    "# for d in [train_img_dir, val_img_dir, test_img_dir, train_mask_dir, val_mask_dir, test_mask_dir]:\n",
    "#     os.makedirs(d, exist_ok=True)\n",
    "\n",
    "# # Get and shuffle list of image filenames\n",
    "# all_images = [f for f in os.listdir(damaged_img_dir) if f.lower().endswith('.png')]\n",
    "# random.seed(42)\n",
    "# random.shuffle(all_images)\n",
    "\n",
    "# # Compute split indices\n",
    "# n_total = len(all_images)\n",
    "# n_train = int(0.70 * n_total)\n",
    "# n_val = int(0.15 * n_total)\n",
    "# n_test = n_total - n_train - n_val\n",
    "\n",
    "# # Split images\n",
    "# train_images = all_images[:n_train]\n",
    "# val_images = all_images[n_train:n_train + n_val]\n",
    "# test_images = all_images[n_train + n_val:]\n",
    "\n",
    "# # Copy function\n",
    "# def copy_files(img_list, target_img_dir, target_mask_dir):\n",
    "#     for fname in img_list:\n",
    "#         src_img_path = os.path.join(damaged_img_dir, fname)\n",
    "#         dst_img_path = os.path.join(target_img_dir, fname)\n",
    "#         shutil.copy(src_img_path, dst_img_path)\n",
    "\n",
    "#         base_name = fname.replace('.png', '')\n",
    "#         mask_name = f'{base_name}-mask.png'\n",
    "#         src_mask_path = os.path.join(damage_mask_dir, mask_name)\n",
    "#         dst_mask_path = os.path.join(target_mask_dir, mask_name)\n",
    "#         if os.path.exists(src_mask_path):\n",
    "#             shutil.copy(src_mask_path, dst_mask_path)\n",
    "#         else:\n",
    "#             print(f'Warning: mask for {fname} not found')\n",
    "\n",
    "# # Perform copying\n",
    "# copy_files(train_images, train_img_dir, train_mask_dir)\n",
    "# copy_files(val_images, val_img_dir, val_mask_dir)\n",
    "# copy_files(test_images, test_img_dir, test_mask_dir)\n",
    "\n",
    "# print(f\"Split complete: {len(train_images)} train, {len(val_images)} val, {len(test_images)} test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a0cd258-38d7-4093-aab2-dbfcc7e7e2cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T10:45:40.170559Z",
     "iopub.status.busy": "2025-05-29T10:45:40.170253Z",
     "iopub.status.idle": "2025-05-29T10:45:40.176413Z",
     "shell.execute_reply": "2025-05-29T10:45:40.174863Z",
     "shell.execute_reply.started": "2025-05-29T10:45:40.170529Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Directories for training set\n",
    "# img_train_dir = '../../data/damaged-and-mask-dataset/img/train'\n",
    "# mask_train_dir = '../../data/damaged-and-mask-dataset/mask/train'\n",
    "\n",
    "# # List all image and mask files\n",
    "# damaged_train = [f for f in os.listdir(img_train_dir) if os.path.isfile(os.path.join(img_train_dir, f))]\n",
    "# mask_train = [f for f in os.listdir(mask_train_dir) if os.path.isfile(os.path.join(mask_train_dir, f))]\n",
    "\n",
    "# # Print samples\n",
    "# print(f'   Sample Mask Files (Train) \\n{mask_train[:5]}')\n",
    "# print(f'   Sample Damaged Image Files (Train) \\n{damaged_train[:5]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f96762-1e88-4173-b42d-cc600382b48e",
   "metadata": {},
   "source": [
    "## Directories for Damaged and Mask Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35ae9c32-a557-4155-93af-de2dd5c2d197",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T10:45:40.177622Z",
     "iopub.status.busy": "2025-05-29T10:45:40.177346Z",
     "iopub.status.idle": "2025-05-29T10:45:40.185327Z",
     "shell.execute_reply": "2025-05-29T10:45:40.183900Z",
     "shell.execute_reply.started": "2025-05-29T10:45:40.177595Z"
    }
   },
   "outputs": [],
   "source": [
    "# Data Handling\n",
    "DATA_DIR = \"../../data/\"\n",
    "\n",
    "x_train_dir = os.path.join(DATA_DIR, \"damaged-and-mask-dataset/img-with-val/train\")\n",
    "y_train_dir = os.path.join(DATA_DIR, \"damaged-and-mask-dataset/mask-with-val/train\")\n",
    "\n",
    "x_valid_dir = os.path.join(DATA_DIR, \"damaged-and-mask-dataset/img-with-val/val\")\n",
    "y_valid_dir = os.path.join(DATA_DIR, \"damaged-and-mask-dataset/mask-with-val/val\")\n",
    "\n",
    "x_test_dir = os.path.join(DATA_DIR, \"damaged-and-mask-dataset/img-with-val/test/\")\n",
    "y_test_dir = os.path.join(DATA_DIR, \"damaged-and-mask-dataset/mask-with-val/test/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c2b6f93-f112-4d7c-84e5-ede67e32796f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T10:45:40.186587Z",
     "iopub.status.busy": "2025-05-29T10:45:40.186309Z",
     "iopub.status.idle": "2025-05-29T10:45:40.192994Z",
     "shell.execute_reply": "2025-05-29T10:45:40.191393Z",
     "shell.execute_reply.started": "2025-05-29T10:45:40.186560Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Define the directories of the paintings and masks\n",
    "# IMAGE_DIR = \"../../data/damaged-and-mask-dataset/generated-damaged-images\"\n",
    "# MASK_DIR = \"../../data/damaged-and-mask-dataset/generated-damage-masks\"\n",
    "\n",
    "# # Clean up the filenames of the paintings and masks\n",
    "# image_filenames = sorted([f for f in os.listdir(IMAGE_DIR) if f.endswith(\".png\")])\n",
    "# mask_filenames = [f.replace(\".png\", \"-mask.png\") for f in image_filenames]\n",
    "\n",
    "# # Define the filepaths\n",
    "# image_paths = [os.path.join(IMAGE_DIR, f) for f in image_filenames]\n",
    "# mask_paths = [os.path.join(MASK_DIR, f) for f in mask_filenames]\n",
    "\n",
    "# # Split the dataset into train-val-test\n",
    "# x_train_dir, X_temp_dir, y_train_dir, y_temp_dir = train_test_split(image_paths, mask_paths, \n",
    "#                                                     test_size=0.3, random_state=42)\n",
    "\n",
    "# x_valid_dir, x_test_dir, y_valid_dir, y_test_dir = train_test_split(X_temp_dir, y_temp_dir, \n",
    "#                                                 test_size = 0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe50a38-f258-4e64-abbc-d1ec49b782c5",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "697a96f5-ea76-474c-b4eb-009aaa5ce53c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T10:45:40.196490Z",
     "iopub.status.busy": "2025-05-29T10:45:40.196203Z",
     "iopub.status.idle": "2025-05-29T10:45:40.205939Z",
     "shell.execute_reply": "2025-05-29T10:45:40.204318Z",
     "shell.execute_reply.started": "2025-05-29T10:45:40.196462Z"
    }
   },
   "outputs": [],
   "source": [
    "# helper function for data visualization\n",
    "def visualize(**images):\n",
    "    \"\"\"PLot images in one row.\"\"\"\n",
    "    n = len(images)\n",
    "    plt.figure(figsize=(16, 5))\n",
    "    for i, (name, image) in enumerate(images.items()):\n",
    "        plt.subplot(1, n, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(' '.join(name.split('_')).title())\n",
    "        plt.imshow(image)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# helper function for data visualization    \n",
    "def denormalize(x):\n",
    "    \"\"\"Scale image to range 0..1 for correct plot\"\"\"\n",
    "    x_max = np.percentile(x, 98)\n",
    "    x_min = np.percentile(x, 2)    \n",
    "    x = (x - x_min) / (x_max - x_min)\n",
    "    x = x.clip(0, 1)\n",
    "    return x\n",
    "\n",
    "\n",
    "def round_clip_0_1(x, **kwargs):\n",
    "    return x.round().clip(0, 1)\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285076ac-baa5-475a-af03-921af48fc9df",
   "metadata": {},
   "source": [
    "## Data Augmentation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52adaa82-2fd4-4889-af2a-03ae7fb41776",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T10:45:40.207381Z",
     "iopub.status.busy": "2025-05-29T10:45:40.207101Z",
     "iopub.status.idle": "2025-05-29T10:45:40.218355Z",
     "shell.execute_reply": "2025-05-29T10:45:40.217240Z",
     "shell.execute_reply.started": "2025-05-29T10:45:40.207354Z"
    }
   },
   "outputs": [],
   "source": [
    "# define heavy augmentations\n",
    "def get_training_augmentation(height, width):\n",
    "    train_transform = [\n",
    "\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "\n",
    "        A.Affine(scale_limit=0.6, rotate_limit=0, shift_limit=0.1, p=1, border_mode=0),\n",
    "\n",
    "        A.PadIfNeeded(min_height=height, min_width=width, border_mode=0),\n",
    "        A.RandomCrop(height=height, width=width),\n",
    "\n",
    "        A.GaussNoise(p=0.2),  # Already correct\n",
    "        A.Perspective(scale=(0.05, 0.1), p=0.5),  # Replacement for IAAPerspective\n",
    "\n",
    "        A.OneOf(\n",
    "            [\n",
    "                A.CLAHE(p=1),\n",
    "                A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0, p=1),\n",
    "                A.RandomGamma(p=1),\n",
    "            ],\n",
    "            p=0.9,\n",
    "        ),\n",
    "\n",
    "        A.OneOf(\n",
    "            [\n",
    "                A.Sharpen(p=1),  # Replacement for IAASharpen\n",
    "                A.Blur(blur_limit=3, p=1),\n",
    "                A.MotionBlur(blur_limit=3, p=1),\n",
    "            ],\n",
    "            p=0.9,\n",
    "        ),\n",
    "\n",
    "        A.OneOf(\n",
    "            [\n",
    "                A.RandomBrightnessContrast(brightness_limit=0, contrast_limit=0.2, p=1),\n",
    "                A.HueSaturationValue(p=1),\n",
    "            ],\n",
    "            p=0.9,\n",
    "        ),\n",
    "        A.Lambda(mask=round_clip_0_1)\n",
    "    ]\n",
    "    return A.Compose(train_transform)\n",
    "\n",
    "\n",
    "def get_validation_augmentation(height, width):\n",
    "    \"\"\"Add paddings to make image shape divisible by 32\"\"\"\n",
    "    test_transform = [\n",
    "        A.PadIfNeeded(height, width),\n",
    "        A.Resize(height, width)\n",
    "    ]\n",
    "    return A.Compose(test_transform)\n",
    "\n",
    "\n",
    "def data_get_preprocessing(preprocessing_fn):\n",
    "    \"\"\"Construct preprocessing transform\n",
    "    \n",
    "    Args:\n",
    "        preprocessing_fn (callbale): data normalization function \n",
    "            (can be specific for each pretrained neural network)\n",
    "    Return:\n",
    "        transform: albumentations.Compose\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    _transform = [\n",
    "        A.Lambda(image=preprocessing_fn),\n",
    "    ]\n",
    "    return A.Compose(_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f027a7-6e9e-4cac-b5bd-5d7d7646e240",
   "metadata": {},
   "source": [
    "## Define some global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebfd5f28-d0f4-4c30-a762-bb15f5e9d2f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T10:45:40.219424Z",
     "iopub.status.busy": "2025-05-29T10:45:40.219149Z",
     "iopub.status.idle": "2025-05-29T10:45:40.226206Z",
     "shell.execute_reply": "2025-05-29T10:45:40.225154Z",
     "shell.execute_reply.started": "2025-05-29T10:45:40.219399Z"
    }
   },
   "outputs": [],
   "source": [
    "TOTAL_CLASSES = [\"painting\", \"damage_mask\"]\n",
    "N_TOTAL_CLASSES = 2\n",
    "\n",
    "with open(\"class_pixel_counts.json\", \"r\") as f:\n",
    "    CLASSES_PIXEL_COUNT_DICT = json.load(f)\n",
    "\n",
    "MODEL_CLASSES = TOTAL_CLASSES\n",
    "BATCH_SIZE = 4\n",
    "N_CLASSES = 1 # Binary segmentation: pixel is either damage or painting\n",
    "HEIGHT = 320\n",
    "WIDTH = 320\n",
    "BACKBONE_NAME = \"resnet50\"\n",
    "WEIGHTS = \"imagenet\"\n",
    "WWO_AUG = True # Train data with and without augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca50b90-4cab-4b53-82be-bf62098031f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T01:11:41.027473Z",
     "iopub.status.busy": "2025-05-29T01:11:41.026652Z",
     "iopub.status.idle": "2025-05-29T01:11:41.042798Z",
     "shell.execute_reply": "2025-05-29T01:11:41.036819Z",
     "shell.execute_reply.started": "2025-05-29T01:11:41.027396Z"
    }
   },
   "source": [
    "## Functions to calculate appropriate class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba94b65d-dca9-4b0b-a850-047d96a5cb95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T10:45:40.227490Z",
     "iopub.status.busy": "2025-05-29T10:45:40.227227Z",
     "iopub.status.idle": "2025-05-29T10:45:40.238515Z",
     "shell.execute_reply": "2025-05-29T10:45:40.237467Z",
     "shell.execute_reply.started": "2025-05-29T10:45:40.227465Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.55 5.82]\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# Class Weights\n",
    "################################################################################\n",
    "def get_dataset_counts(d):\n",
    "    pixel_count = np.array([i for i in d.values()])\n",
    "\n",
    "    sum_pixel_count = 0\n",
    "    for i in pixel_count:\n",
    "        sum_pixel_count += i\n",
    "\n",
    "    return pixel_count, sum_pixel_count\n",
    "\n",
    "\n",
    "def get_dataset_statistics(pixel_count, sum_pixel_count):\n",
    "    \n",
    "    pixel_frequency = np.round(pixel_count / sum_pixel_count, 4)\n",
    "\n",
    "    mean_pixel_frequency = np.round(np.mean(pixel_frequency), 4)\n",
    "\n",
    "    return pixel_frequency, mean_pixel_frequency\n",
    "\n",
    "\n",
    "def get_balancing_class_weights(classes, d):\n",
    "    pixel_count, sum_pixel_count = get_dataset_counts(d)\n",
    "\n",
    "    background_pixel_count = 0\n",
    "    mod_pixel_count = []\n",
    "    for c in TOTAL_CLASSES:\n",
    "        if c not in classes:\n",
    "            background_pixel_count += d[c]\n",
    "        else:\n",
    "            mod_pixel_count.append(d[c])\n",
    "\n",
    "    if background_pixel_count > 0:\n",
    "        mod_pixel_count.append(background_pixel_count)\n",
    "\n",
    "    pixel_frequency, mean_pixel_frequency = get_dataset_statistics(mod_pixel_count, sum_pixel_count)\n",
    "\n",
    "    # Avoid division by zero\n",
    "    pixel_frequency = np.where(pixel_frequency == 0, 1e-8, pixel_frequency)\n",
    "\n",
    "    class_weights = np.round(mean_pixel_frequency / pixel_frequency, 2)\n",
    "    return class_weights\n",
    "\n",
    "\n",
    "class_weights = get_balancing_class_weights(MODEL_CLASSES, CLASSES_PIXEL_COUNT_DICT)\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd40caff-d5b1-4a59-b9b0-a9b3da157007",
   "metadata": {},
   "source": [
    "## Data Generation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e44eca5-12ac-43df-bd8f-79e91859bf70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T10:45:40.240028Z",
     "iopub.status.busy": "2025-05-29T10:45:40.239716Z",
     "iopub.status.idle": "2025-05-29T10:45:40.257466Z",
     "shell.execute_reply": "2025-05-29T10:45:40.256449Z",
     "shell.execute_reply.started": "2025-05-29T10:45:40.240000Z"
    }
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Data Generator\n",
    "################################################################################\n",
    "def create_image_label_path_generator(images_dir, masks_dir, shuffle=False, seed=None):\n",
    "    ids = sorted(os.listdir(images_dir))\n",
    "    mask_ids = sorted(os.listdir(masks_dir))\n",
    "\n",
    "    if shuffle == True:\n",
    "\n",
    "        if seed is not None:\n",
    "            tf.random.set_seed(seed)\n",
    "\n",
    "        indices = tf.range(start=0, limit=tf.shape(ids)[0], dtype=tf.int32)\n",
    "        shuffled_indices = tf.random.shuffle(indices)\n",
    "\n",
    "        ids = tf.gather(ids, shuffled_indices).numpy().astype(str)\n",
    "        mask_ids = tf.gather(mask_ids, shuffled_indices).numpy().astype(str)\n",
    "\n",
    "    images_fps = [os.path.join(images_dir, image_id) for image_id in ids]\n",
    "    masks_fps = [os.path.join(masks_dir, image_id) for image_id in mask_ids]\n",
    "\n",
    "    while True:\n",
    "        for i in range(len(images_fps)):\n",
    "            yield [images_fps[i], masks_fps[i]]\n",
    "\n",
    "\n",
    "def process_image_label(images_paths, masks_paths, classes, augmentation=None, preprocessing=None):\n",
    "    class_values = [TOTAL_CLASSES.index(cls.lower()) for cls in classes]\n",
    "    \n",
    "    # read data\n",
    "    image = cv2.imread(images_paths)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    mask = cv2.imread(masks_paths, 0)\n",
    "\n",
    "    # extract certain classes from mask (e.g. cars)\n",
    "    masks = [(mask == v) for v in class_values]\n",
    "    mask = np.stack(masks, axis=-1).astype('float')\n",
    "    \n",
    "    # add background if mask is not binary\n",
    "    if mask.shape[-1] != 1:\n",
    "        background = 1 - mask.sum(axis=-1, keepdims=True)\n",
    "        mask = np.concatenate((mask, background), axis=-1)\n",
    "    \n",
    "    # apply augmentations\n",
    "    if augmentation:\n",
    "        sample = augmentation(image=image, mask=mask)\n",
    "        image, mask = sample['image'], sample['mask']\n",
    "    \n",
    "    # apply preprocessing\n",
    "    if preprocessing:\n",
    "        sample = preprocessing(image=image, mask=mask)\n",
    "        image, mask = sample['image'], sample['mask']\n",
    "\n",
    "    # mask = np.squeeze(np.argmax(mask, axis=-1))\n",
    "    # mask = np.argmax(mask, axis=-1)\n",
    "    # mask = mask[..., np.newaxis]\n",
    "        \n",
    "    return image, mask\n",
    "\n",
    "def DataGenerator(train_dir, label_dir, batch_size, height, width, classes, augmentation, wwo_aug=False, shuffle=False, seed=None):\n",
    "    image_label_path_generator = create_image_label_path_generator(\n",
    "        train_dir, label_dir, shuffle=shuffle, seed=seed\n",
    "    )\n",
    "    if wwo_aug:\n",
    "        while True:\n",
    "            images = np.zeros(shape=[batch_size, height, width, 3])\n",
    "            labels = np.zeros(shape=[batch_size, height, width, len(classes) + 1], dtype=np.float32)\n",
    "            for i in range(0, batch_size, 2):\n",
    "                image_path, label_path = next(image_label_path_generator)\n",
    "                image_aug, label_aug = process_image_label(image_path, label_path, classes=classes, augmentation=augmentation)\n",
    "                image_wo_aug, label_wo_aug = process_image_label(image_path, label_path, classes=classes, augmentation=get_validation_augmentation(height=HEIGHT, width=WIDTH))\n",
    "                images[i], labels[i] = image_aug, label_aug\n",
    "                images[i + 1], labels[i + 1] = image_wo_aug, label_wo_aug\n",
    "\n",
    "            yield tf.convert_to_tensor(images), tf.convert_to_tensor(labels, tf.float32)\n",
    "    else:\n",
    "        while True:\n",
    "            images = np.zeros(shape=[batch_size, height, width, 3])\n",
    "            labels = np.zeros(shape=[batch_size, height, width, len(classes) + 1], dtype=np.float32)\n",
    "            for i in range(batch_size):\n",
    "                image_path, label_path = next(image_label_path_generator)\n",
    "                image, label = process_image_label(image_path, label_path, classes=classes, augmentation=augmentation)\n",
    "                images[i], labels[i] = image, label\n",
    "\n",
    "            yield tf.convert_to_tensor(images), tf.convert_to_tensor(labels, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2885be5d-4002-4337-8492-b6eb837c51df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T10:45:40.258467Z",
     "iopub.status.busy": "2025-05-29T10:45:40.258237Z",
     "iopub.status.idle": "2025-05-29T10:45:40.266249Z",
     "shell.execute_reply": "2025-05-29T10:45:40.265272Z",
     "shell.execute_reply.started": "2025-05-29T10:45:40.258444Z"
    }
   },
   "outputs": [],
   "source": [
    "# ################################################################################\n",
    "# # Data Generator\n",
    "# ################################################################################\n",
    "# def create_image_label_path_generator(image_paths, mask_paths, shuffle=False, seed=None):\n",
    "#     if shuffle:\n",
    "#         combined = list(zip(image_paths, mask_paths))\n",
    "#         rng = np.random.default_rng(seed)\n",
    "#         rng.shuffle(combined)\n",
    "#         image_paths, mask_paths = zip(*combined)\n",
    "\n",
    "#     for img_path, mask_path in zip(image_paths, mask_paths):\n",
    "#         yield img_path, mask_path\n",
    "\n",
    "\n",
    "# def process_image_label(images_paths, masks_paths, classes, augmentation=None, preprocessing=None):\n",
    "#     class_values = [TOTAL_CLASSES.index(cls.lower()) for cls in classes]\n",
    "    \n",
    "#     # read data\n",
    "#     image = cv2.imread(images_paths)\n",
    "#     image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "#     mask = cv2.imread(masks_paths, 0)\n",
    "\n",
    "#     # extract certain classes from mask (e.g. cars)\n",
    "#     masks = [(mask == v) for v in class_values]\n",
    "#     mask = np.stack(masks, axis=-1).astype('float')\n",
    "    \n",
    "#     # add background if mask is not binary\n",
    "#     if mask.shape[-1] != 1:\n",
    "#         background = 1 - mask.sum(axis=-1, keepdims=True)\n",
    "#         mask = np.concatenate((mask, background), axis=-1)\n",
    "    \n",
    "#     # apply augmentations\n",
    "#     if augmentation:\n",
    "#         sample = augmentation(image=image, mask=mask)\n",
    "#         image, mask = sample['image'], sample['mask']\n",
    "    \n",
    "#     # apply preprocessing\n",
    "#     if preprocessing:\n",
    "#         sample = preprocessing(image=image, mask=mask)\n",
    "#         image, mask = sample['image'], sample['mask']\n",
    "\n",
    "#     # mask = np.squeeze(np.argmax(mask, axis=-1))\n",
    "#     # mask = np.argmax(mask, axis=-1)\n",
    "#     # mask = mask[..., np.newaxis]\n",
    "        \n",
    "#     return image, mask\n",
    "\n",
    "\n",
    "# def DataGenerator(train_dir, label_dir, batch_size, height, width, classes, augmentation, wwo_aug=False, shuffle=False, seed=None):\n",
    "#     image_label_path_generator = create_image_label_path_generator(\n",
    "#         train_dir, label_dir, shuffle=shuffle, seed=seed\n",
    "#     )\n",
    "#     if wwo_aug:\n",
    "#         while True:\n",
    "#             images = np.zeros(shape=[batch_size, height, width, 3])\n",
    "#             labels = np.zeros(shape=[batch_size, height, width, len(classes) + 1], dtype=np.float32)\n",
    "#             for i in range(0, batch_size, 2):\n",
    "#                 image_path, label_path = next(image_label_path_generator)\n",
    "#                 image_aug, label_aug = process_image_label(image_path, label_path, classes=classes, augmentation=augmentation)\n",
    "#                 image_wo_aug, label_wo_aug = process_image_label(image_path, label_path, classes=classes, augmentation=get_validation_augmentation(height=HEIGHT, width=WIDTH))\n",
    "#                 images[i], labels[i] = image_aug, label_aug\n",
    "#                 images[i + 1], labels[i + 1] = image_wo_aug, label_wo_aug\n",
    "\n",
    "#             yield tf.convert_to_tensor(images), tf.convert_to_tensor(labels, tf.float32)\n",
    "#     else:\n",
    "#         while True:\n",
    "#             images = np.zeros(shape=[batch_size, height, width, 3])\n",
    "#             labels = np.zeros(shape=[batch_size, height, width, len(classes) + 1], dtype=np.float32)\n",
    "#             for i in range(batch_size):\n",
    "#                 image_path, label_path = next(image_label_path_generator)\n",
    "#                 image, label = process_image_label(image_path, label_path, classes=classes, augmentation=augmentation)\n",
    "#                 images[i], labels[i] = image, label\n",
    "\n",
    "#             yield tf.convert_to_tensor(images), tf.convert_to_tensor(labels, tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8828781a-b0ef-4b3d-82dc-ffec251de92f",
   "metadata": {},
   "source": [
    "## Create the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0664ef63-a9ca-45ae-938c-fc090e6c022b",
   "metadata": {},
   "source": [
    "**NOTE:** Change to U-Net, if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60774315-e771-4152-bbed-4c912ece6c7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T10:45:40.267216Z",
     "iopub.status.busy": "2025-05-29T10:45:40.266995Z",
     "iopub.status.idle": "2025-05-29T10:45:43.358072Z",
     "shell.execute_reply": "2025-05-29T10:45:43.356873Z",
     "shell.execute_reply.started": "2025-05-29T10:45:40.267193Z"
    }
   },
   "outputs": [],
   "source": [
    "base_model, layers, layer_names = tasm.create_base_model(name=BACKBONE_NAME, weights=WEIGHTS, height=HEIGHT, width=WIDTH, include_top=False, pooling=None)\n",
    "\n",
    "BACKBONE_TRAINABLE = False\n",
    "model = tasm.UNet(n_classes=N_CLASSES, base_model=base_model, output_layers=layers, backbone_trainable=BACKBONE_TRAINABLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bfafc9-425e-4e14-882a-1c0470f85811",
   "metadata": {},
   "source": [
    "### Define the optimizer, losses, metrics, and callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30f7126b-4d7e-4b93-ab99-afd5ce008313",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T10:45:43.359034Z",
     "iopub.status.busy": "2025-05-29T10:45:43.358825Z",
     "iopub.status.idle": "2025-05-29T10:45:43.376120Z",
     "shell.execute_reply": "2025-05-29T10:45:43.374299Z",
     "shell.execute_reply.started": "2025-05-29T10:45:43.359013Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define optimizer (Adam adapts learning rates per parameter)\n",
    "opt = tf.keras.optimizers.Adam(\n",
    "    learning_rate=1e-4,\n",
    "    epsilon=1e-7\n",
    ")\n",
    "\n",
    "# Use IoU as the primary performance metric\n",
    "metrics = [tasm.metrics.IOUScore(threshold=0.5)]\n",
    "\n",
    "# Combine Binary Focal Loss (for class imbalance) with Dice Loss (for region overlap)\n",
    "binary_focal_dice_loss = (\n",
    "    tasm.losses.BinaryFocalLoss(alpha=0.25, gamma=2.0) +\n",
    "    tasm.losses.DiceLoss()\n",
    ")\n",
    "\n",
    "# Compile the model with optimizer, loss function, and evaluation metric\n",
    "model.compile(\n",
    "    optimizer=opt,\n",
    "    loss=binary_focal_dice_loss,\n",
    "    metrics=metrics,\n",
    ")\n",
    "\n",
    "# Run model in eager mode (easier debugging, slightly slower)\n",
    "model.run_eagerly = True\n",
    "\n",
    "# Define training callbacks\n",
    "callbacks = [\n",
    "    # Save full model (architecture + weights) only when IoU improves\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"models/DeepLabv3plus_full_model.keras\",\n",
    "        monitor=\"iou_score\",\n",
    "        mode=\"max\",\n",
    "        verbose=1,\n",
    "        save_best_only=True,\n",
    "        save_weights_only=False\n",
    "    ),\n",
    "\n",
    "    # Stop training if no IoU improvement after 16 epochs, and restore best model\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"iou_score\",\n",
    "        patience=16,\n",
    "        mode=\"max\",\n",
    "        verbose=1,\n",
    "        restore_best_weights=True\n",
    "    ),\n",
    "\n",
    "    # Reduce learning rate by a factor of 0.2 if IoU doesn't improve after 6 epochs\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor=\"iou_score\",\n",
    "        factor=0.2,\n",
    "        patience=6,\n",
    "        verbose=1,\n",
    "        mode=\"max\"\n",
    "    ),\n",
    "\n",
    "    # Log training progress for visualization in TensorBoard\n",
    "    tf.keras.callbacks.TensorBoard(\n",
    "        log_dir=\"logs\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7040e1-1fa8-4d0f-b534-13ee4b1b1631",
   "metadata": {},
   "source": [
    "## Get the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61d0b6d1-8939-4189-b575-b94ba66cbc3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T10:45:43.377038Z",
     "iopub.status.busy": "2025-05-29T10:45:43.376792Z",
     "iopub.status.idle": "2025-05-29T10:45:45.416039Z",
     "shell.execute_reply": "2025-05-29T10:45:45.414349Z",
     "shell.execute_reply.started": "2025-05-29T10:45:43.377014Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_136857/2707607068.py:7: UserWarning: Argument(s) 'scale_limit, rotate_limit, shift_limit' are not valid for transform Affine\n",
      "  A.Affine(scale_limit=0.6, rotate_limit=0, shift_limit=0.1, p=1, border_mode=0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "(4, 320, 320, 3)\n",
      "(4, 320, 320, 3)\n",
      "24205\n",
      "5186\n",
      "5188\n"
     ]
    }
   ],
   "source": [
    "train_shuffle = True\n",
    "val_shuffle = True\n",
    "seed = 29598\n",
    "\n",
    "TrainSet = DataGenerator(\n",
    "    x_train_dir,\n",
    "    y_train_dir,\n",
    "    BATCH_SIZE,\n",
    "    HEIGHT,\n",
    "    WIDTH,\n",
    "    classes=MODEL_CLASSES,\n",
    "    augmentation=get_training_augmentation(height=HEIGHT, width=WIDTH),\n",
    "    shuffle=train_shuffle,\n",
    "    seed=seed\n",
    "    )\n",
    "\n",
    "TrainSetwoAug = DataGenerator(\n",
    "    x_train_dir,\n",
    "    y_train_dir,\n",
    "    BATCH_SIZE,\n",
    "    HEIGHT,\n",
    "    WIDTH,\n",
    "    classes=MODEL_CLASSES,\n",
    "    augmentation=get_validation_augmentation(height=HEIGHT, width=WIDTH),\n",
    "    shuffle=train_shuffle,\n",
    "    seed=seed\n",
    ")\n",
    "\n",
    "TrainSetwwoAug = DataGenerator(\n",
    "    x_train_dir,\n",
    "    y_train_dir,\n",
    "    BATCH_SIZE,\n",
    "    HEIGHT,\n",
    "    WIDTH,\n",
    "    classes=MODEL_CLASSES,\n",
    "    augmentation=get_training_augmentation(height=HEIGHT, width=WIDTH),\n",
    "    wwo_aug=True,\n",
    "    shuffle=train_shuffle,\n",
    "    seed=seed\n",
    ")\n",
    "\n",
    "ValidationSet = DataGenerator(\n",
    "    x_valid_dir,\n",
    "    y_valid_dir,\n",
    "    1,\n",
    "    HEIGHT,\n",
    "    WIDTH,\n",
    "    classes=MODEL_CLASSES,\n",
    "    augmentation=get_validation_augmentation(height=HEIGHT, width=WIDTH),\n",
    "    shuffle=val_shuffle,\n",
    "    seed=seed\n",
    ")\n",
    "\n",
    "TestSet = DataGenerator(\n",
    "    x_test_dir,\n",
    "    y_test_dir,\n",
    "    1,\n",
    "    HEIGHT,\n",
    "    WIDTH,\n",
    "    classes=MODEL_CLASSES,\n",
    "    augmentation=get_validation_augmentation(height=HEIGHT, width=WIDTH),\n",
    ")\n",
    "\n",
    "for i in TrainSet:\n",
    "    sample_image, sample_mask = i[0][0], i[1][0]\n",
    "    print(len(i))\n",
    "    print(i[0].shape)\n",
    "    print(i[1].shape)\n",
    "    break\n",
    "\n",
    "print(len(os.listdir(x_train_dir)))\n",
    "print(len(os.listdir(x_valid_dir)))\n",
    "print(len(os.listdir(x_test_dir)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a761af-0e31-4f56-9d3b-d3dd6a42af46",
   "metadata": {},
   "source": [
    "Quick check if the model works properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "125b7626-12ed-473a-8692-c6e2d6e4c0f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T10:45:45.417347Z",
     "iopub.status.busy": "2025-05-29T10:45:45.417067Z",
     "iopub.status.idle": "2025-05-29T10:45:45.427049Z",
     "shell.execute_reply": "2025-05-29T10:45:45.425820Z",
     "shell.execute_reply.started": "2025-05-29T10:45:45.417320Z"
    }
   },
   "outputs": [],
   "source": [
    "def display(display_list):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
    "\n",
    "    for i in range(len(display_list)):\n",
    "        plt.subplot(1, len(display_list), i+1)\n",
    "        plt.title(title[i])\n",
    "        plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]), cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def create_mask(pred_mask):\n",
    "    # Convert sigmoid output to binary mask with threshold 0.5\n",
    "    pred_mask = tf.where(pred_mask > 0.5, 1.0, 0.0)\n",
    "    return pred_mask[0]\n",
    "\n",
    "\n",
    "def show_predictions(model, sample_image, sample_mask, loss_fn):\n",
    "    pred_output = model(sample_image[tf.newaxis, ...], training=False)\n",
    "    pred_mask = create_mask(pred_output)\n",
    "\n",
    "    bce = tf.keras.losses.BinaryCrossentropy()\n",
    "    print(\"BinaryCrossentropy:\", bce(sample_mask, pred_output[0]).numpy())\n",
    "    print(\"IoU Score:\", tasm.losses.iou_score(sample_mask, pred_output[0]).numpy())\n",
    "    print(\"Binary Focal + Dice Loss:\", loss_fn(sample_mask, pred_output[0]).numpy())\n",
    "\n",
    "    display([sample_image, sample_mask, pred_mask])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0903624-d6fe-4f98-9fb5-dd4e0f6d3e77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T10:45:45.429826Z",
     "iopub.status.busy": "2025-05-29T10:45:45.429137Z",
     "iopub.status.idle": "2025-05-29T10:45:45.437663Z",
     "shell.execute_reply": "2025-05-29T10:45:45.435927Z",
     "shell.execute_reply.started": "2025-05-29T10:45:45.429739Z"
    }
   },
   "outputs": [],
   "source": [
    "tf.debugging.set_log_device_placement(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb45c001-3f8e-4da7-a631-b159cc1fa109",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in ValidationSet:\n",
    "    sample_image, sample_mask = batch[0][0], batch[1][0]\n",
    "    break\n",
    "\n",
    "show_predictions(model, sample_image, sample_mask, binary_focal_dice_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613b0b3f-ec92-4e14-b191-b8d02bfb7f9c",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-29T10:45:48.953295Z",
     "iopub.status.idle": "2025-05-29T10:45:48.953560Z",
     "shell.execute_reply": "2025-05-29T10:45:48.953438Z",
     "shell.execute_reply.started": "2025-05-29T10:45:48.953425Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e15b5a6-3c51-41db-9a9f-17db010af6fa",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-29T10:45:48.954562Z",
     "iopub.status.idle": "2025-05-29T10:45:48.954848Z",
     "shell.execute_reply": "2025-05-29T10:45:48.954720Z",
     "shell.execute_reply.started": "2025-05-29T10:45:48.954707Z"
    }
   },
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09d0d88-eb94-4274-8c74-f53f363ce733",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-art-restoration-ai]",
   "language": "python",
   "name": "conda-env-.conda-art-restoration-ai-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
