{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23f44ab9-b01e-4682-a489-0b6ea3c769d5",
   "metadata": {},
   "source": [
    "# For the Human Touch\n",
    "Human-In-The-Loop implementation of the damage detection task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02d22ba9-e832-477c-8c0b-707390e13e7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-03T17:19:35.230350Z",
     "iopub.status.busy": "2025-06-03T17:19:35.229653Z",
     "iopub.status.idle": "2025-06-03T17:19:39.374621Z",
     "shell.execute_reply": "2025-06-03T17:19:39.373128Z",
     "shell.execute_reply.started": "2025-06-03T17:19:35.230290Z"
    }
   },
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a215cf52-4cca-4c67-89ae-cba28b881fad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-03T17:30:19.524005Z",
     "iopub.status.busy": "2025-06-03T17:30:19.523260Z",
     "iopub.status.idle": "2025-06-03T17:30:23.263278Z",
     "shell.execute_reply": "2025-06-03T17:30:23.261698Z",
     "shell.execute_reply.started": "2025-06-03T17:30:19.523945Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7871\n",
      "* Running on public URL: https://6adc6064d706fa9ba9.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://6adc6064d706fa9ba9.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "damaged_image = \"../../data/predicted_original.png\"\n",
    "mask = \"../../data/predicted_mask.png\"\n",
    "\n",
    "def overlay_mask_on_image(image_path, mask_path, alpha=0.5):\n",
    "    if not os.path.exists(image_path) or not os.path.exists(mask_path):\n",
    "        raise FileNotFoundError(\"One or both image paths are invalid.\")\n",
    "    \n",
    "    image = cv2.imread(image_path)\n",
    "    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # Resize mask to match image if needed\n",
    "    if mask.shape != image.shape[:2]:\n",
    "        mask = cv2.resize(mask, (image.shape[1], image.shape[0]))\n",
    "\n",
    "    # Make overlay: red where mask = 255\n",
    "    overlay = image.copy()\n",
    "    overlay[mask > 0] = [0, 0, 255]  # red\n",
    "\n",
    "    # Blend with alpha\n",
    "    blended = cv2.addWeighted(image, 1 - alpha, overlay, alpha, 0)\n",
    "    return cv2.cvtColor(blended, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "def save_edited_mask(edited_data):\n",
    "    # Load original predicted mask (ensure it's 8-bit grayscale 0/255)\n",
    "    orig_mask = cv2.imread(mask, cv2.IMREAD_GRAYSCALE)\n",
    "    if orig_mask is None:\n",
    "        raise FileNotFoundError(\"unet_mask.png not found\")\n",
    "\n",
    "    if isinstance(edited_data, dict) and \"composite\" in edited_data:\n",
    "        composite = edited_data[\"composite\"]\n",
    "        background = edited_data[\"background\"]\n",
    "\n",
    "        # Downscale to match original mask size\n",
    "        target_size = (orig_mask.shape[1], orig_mask.shape[0])\n",
    "        composite = cv2.resize(composite, target_size, interpolation=cv2.INTER_NEAREST)\n",
    "        background = cv2.resize(background, target_size, interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        # Convert both to grayscale\n",
    "        composite_gray = cv2.cvtColor(composite, cv2.COLOR_RGB2GRAY)\n",
    "        background_gray = cv2.cvtColor(background, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "        # Extract user corrections\n",
    "        diff = cv2.absdiff(composite_gray, background_gray)\n",
    "        _, user_mask = cv2.threshold(diff, 20, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        # Ensure original mask is binary\n",
    "        _, orig_mask_bin = cv2.threshold(orig_mask, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        # Combine original mask + user corrections\n",
    "        user_mask = cv2.resize(user_mask, (orig_mask_bin.shape[1], orig_mask_bin.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "        final_mask = cv2.bitwise_or(orig_mask_bin, user_mask)\n",
    "\n",
    "        # Save and return for preview\n",
    "        cv2.imwrite(\"mask_corrected.png\", final_mask)\n",
    "        return cv2.cvtColor(final_mask, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "    return np.zeros((320, 320, 3), dtype=np.uint8)\n",
    "\n",
    "\n",
    "# Generate overlay preview\n",
    "# composite_img = overlay_mask_on_image(\"predicted_original.png\", \"predicted_mask.png\")\n",
    "\n",
    "composite_img = overlay_mask_on_image(damaged_image, mask)\n",
    "composite_img_upscaled = cv2.resize(composite_img, None, fx=4, fy=4, interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"### Trace over missing cracks in the predicted mask\")\n",
    "    editor = gr.ImageEditor(label=\"Draw on Mask Overlay\", value=composite_img_upscaled)\n",
    "    save_btn = gr.Button(\"Save Refined Mask\")\n",
    "    output = gr.Image(label=\"Saved Mask Preview\")\n",
    "\n",
    "    save_btn.click(fn=save_edited_mask, inputs=editor, outputs=output)\n",
    "\n",
    "demo.launch(share=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bd8bb0-e3ab-475d-aba1-c05909c97a37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
